{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import HTMLParser\n",
    "import re\n",
    "import itertools\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn import feature_extraction\n",
    "from nltk import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_parser = HTMLParser.HTMLParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.77 s, sys: 912 ms, total: 8.68 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%time en_nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleaning(original_tweet):\n",
    "    tweet = html_parser.unescape(original_tweet)\n",
    "    tweet = original_tweet.decode(\"utf8\").encode('ascii','ignore')\n",
    "    APPOSTOPHES = {\"'s\" : \" is\", \"'re\" : \" are\"}\n",
    "    words = tweet.split()\n",
    "    reformed = [APPOSTOPHES[word] if word in APPOSTOPHES else word for word in words]\n",
    "    reformed = \" \".join(reformed)\n",
    "    cleaned = \" \".join(re.findall('[A-Z][^A-Z]*', original_tweet))\n",
    "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(tweet))\n",
    "    result = re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    s = re.sub(\"\\d+\", \"\", result)\n",
    "    line = re.sub('[!@#$>&<]', '',s)\n",
    "    return line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RatedWordgroup:\n",
    "    def __init__(self,wordgroup,rating):\n",
    "        self.wordgroup = wordgroup\n",
    "        self.rating = rating\n",
    "\n",
    "    def __str__(self):\n",
    "        result = str(self.wordgroup) +\" - \" + str(self.rating)\n",
    "        return result\n",
    "\n",
    "    def __eq__(self,other):\n",
    "        return self.wordgroup.eq(other.wordgroup) and self.rating.eq(other.rating)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RatedSentence:\n",
    "\n",
    "    def __init__(self,position,sentence,rating):\n",
    "        self.position = position\n",
    "        self.sentence = sentence\n",
    "        self.rating = rating\n",
    "\n",
    "    def __str__(self):\n",
    "        result = \"(\" + str(self.position) +\") (\" + str(self.rating) +\") \" + self.sentence\n",
    "        return result\n",
    "\n",
    "    def __eq__(self,other):\n",
    "        return self.position.eq(other.position) and self.sentence.eq(other.sentence) and self.rating.eq(other.rating)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_bag(text) :\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"[^a-Å¾]+\", \" \", text)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"[ ]+\", \" \", text)\n",
    "    wordlist = text.split(\" \")\n",
    "    word_bag = list()\n",
    "    for word in wordlist :\n",
    "        word_bag.append(word.strip())\n",
    "    return word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(text,delimiter='.') :\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"[ ]+\", \" \", text)\n",
    "    sentences = text.split(delimiter)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_words(text) :\n",
    "    word_bag = get_word_bag(text)\n",
    "\n",
    "    cleanset = set()\n",
    "    used_words = set()\n",
    "    word_groups = list()\n",
    "\n",
    "    for word in word_bag :\n",
    "        cleanset.add(word.strip())\n",
    "\n",
    "    for word in cleanset :\n",
    "        if word not in used_words :\n",
    "            wordfamily = list()\n",
    "            wordfamily.append(word)\n",
    "            if(len(word)>2) :\n",
    "                used_words.add(word)\n",
    "                for other in cleanset :\n",
    "                    if other not in used_words :\n",
    "                        same_chars = 0\n",
    "                        (min_len,max_len) = (len(word),len(other)) if len(word) <= len(other) else (len(other),len(word))\n",
    "                        for x in range(0,min_len) :\n",
    "                            if word[x] == other[x] :\n",
    "                                same_chars += 1\n",
    "                            else :\n",
    "                                break\n",
    "                        if same_chars > 3 and (max_len - same_chars) < 7 :\n",
    "                            wordfamily.append(other)\n",
    "                            used_words.add(other)\n",
    "            word_groups.append(wordfamily)\n",
    "    return word_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_wordlist_rate(text) :\n",
    "    word_groups = group_words(text)\n",
    "    word_bag = get_word_bag(text)\n",
    "    rated_word_set = set()\n",
    "    for group in word_groups :\n",
    "        occur = 0\n",
    "        for word in group :\n",
    "            occur += word_bag.count(word)\n",
    "        rated_word_set.add(RatedWordgroup(group,occur))\n",
    "    return rated_word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rate_sentences(text,percentage=10,verbose=True) :\n",
    "    result = str()\n",
    "    sentences = get_sentences(text)\n",
    "    wordlist = get_wordlist_rate(text)\n",
    "    rated = list()\n",
    "    topwords = list()\n",
    "    sort_wg = sorted(wordlist, key = lambda group : group.rating, reverse=True)\n",
    "    for rwg in sort_wg:\n",
    "        if rwg.rating > 1 and len(rwg.wordgroup[0]) > 4 :\n",
    "            #and len(rwg.wordgroup) > 1:\n",
    "            weight = 1\n",
    "            weight += rwg.rating/2\n",
    "            weight += len(rwg.wordgroup[0])/2\n",
    "            weight += len(rwg.wordgroup)/1\n",
    "            for word in rwg.wordgroup :\n",
    "                topwords.append((weight,word))\n",
    "    position = 0\n",
    "    for sentence in sentences :\n",
    "        rating = 0\n",
    "        position += 1\n",
    "        bag = get_word_bag(sentence)\n",
    "        for word in bag :\n",
    "            for record in topwords :\n",
    "                 if word.lower()==record[1]:\n",
    "                    rating += record[0]\n",
    "        if(rating>0 and len(bag) > 0):\n",
    "            if((len(bag)/7) !=0):\n",
    "                rating = rating/((len(bag))/7)\n",
    "            else:\n",
    "                rating=0\n",
    "\n",
    "        rated_sentence = RatedSentence(position, sentence, rating)\n",
    "\n",
    "        rated.append(rated_sentence)\n",
    "\n",
    "    sort_sentences = sorted(rated, key = lambda sen : sen.rating, reverse=True)\n",
    "    num_of_sen = int((len(sentences) / 100.0) * percentage)\n",
    "    unsorted_result = list()\n",
    "\n",
    "    counter = 0\n",
    "    for rs in sort_sentences:\n",
    "        if(counter>num_of_sen):\n",
    "            break\n",
    "        else:\n",
    "            unsorted_result.append(rs)\n",
    "            counter += 1\n",
    "\n",
    "    sort_result = sorted(unsorted_result, key = lambda sen : sen.position, reverse=False)\n",
    "\n",
    "    for rs in sort_result:\n",
    "        result += rs.sentence + \".\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of synopsis  ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synopses_wiki = open('data/synopses_list_wiki.txt').read().split('\\n BREAKS HERE')\n",
    "print(\"Number of synopsis  ----\")\n",
    "len(synopses_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "synopses_wiki = synopses_wiki[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suma=[]\n",
    "\n",
    "for i in synopses_wiki:\n",
    "    suma.append(cleaning(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Sollozzo kidnaps Hagen to pressure Sonny to accept his deal. Sollozzo kidnaps Hagen to pressure Sonny to accept his deal. Michael takes refuge in Sicily, and Fredo Corleone is sheltered by associate Moe Greene in Las Vegas. Michael's time abroad has led to marriage to Apollonia Vitelli. Michael's time abroad has led to marriage to Apollonia Vitelli. He denies killing Carlo when questioned by Kay, an answer she accepts. He denies killing Carlo when questioned by Kay, an answer she accepts.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumar=[]\n",
    "\n",
    "for i in suma:\n",
    "    get_sentences(i)\n",
    "    get_wordlist_rate(i)\n",
    "    sumar.append(rate_sentences(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def stopword_removal(text1):\n",
    "    tex=text1.split()\n",
    "    text = ' '.join([word for word in tex if word not in stopwords.words('english')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopsum=[]\n",
    "for i in sumar:\n",
    "    stopsum.append(stopword_removal(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts=[]\n",
    "tj=[]\n",
    "for i in stopsum:\n",
    "    ts.append(tokenize_and_stem(i))\n",
    "    \n",
    "for i in ts:\n",
    "    tj.append(' '.join(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc=[]\n",
    "\n",
    "for i in tj:\n",
    "    doc.append(en_nlp(i.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Matgra:\n",
    "    \n",
    "    def __init__(self, dc,a):\n",
    "        self.dG=a\n",
    "        self.doc=dc\n",
    "        \n",
    "    def to_nod(self,node):\n",
    "        if not self.dG.has_node(node):\n",
    "            self.dG.add_node(node)\n",
    "        if node.n_lefts + node.n_rights > 0:\n",
    "            for child in node.children:\n",
    "                self.dG.add_edge(node,child)\n",
    "                self.to_nod(child)\n",
    "        \n",
    "    def to_send(self):\n",
    "        [self.to_nod(sent.root) for sent in self.doc.sents]\n",
    "        \n",
    "    def to_res(self):\n",
    "        self.to_send()\n",
    "        a=nx.to_numpy_matrix(self.dG)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=[]\n",
    "\n",
    "for i in doc:\n",
    "    dG = nx.DiGraph()\n",
    "    b=Matgra(i,dG)\n",
    "    res.append(b.to_res())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    s=0\n",
    "    def __init__(self, graph):\n",
    "        self.graph = np.asarray(graph)\n",
    "        self.graphSize = graph.shape[0]\n",
    "        s=graph.shape[0]\n",
    "        self.nodeList=[]\n",
    "        self.inDegreeNodeList = [[] for _ in range(s)]\n",
    "        self.outDegreeNodeList = [[] for _ in range(s)]\n",
    "     \n",
    "    def setInDegreeNodeList(self):\n",
    "        for i in range(0, self.graphSize):\n",
    "            for j in range(0, self.graphSize):\n",
    "                if self.graph[i][j] != 0:\n",
    "                    self.inDegreeNodeList[j].append(i)\n",
    "    \n",
    "            \n",
    "    def setOutDegreeNodeList(self): \n",
    "        for i in range(0, self.graphSize):\n",
    "            for j in range(0, self.graphSize):\n",
    "                if self.graph[i][j] != 0:\n",
    "                    self.outDegreeNodeList[i].append(j)\n",
    "            \n",
    "    def getGraph(self):\n",
    "        return self.graph\n",
    "\n",
    "    def getGraphSize(self):\n",
    "        return self.graphSize\n",
    "\n",
    "    def getInDegreeNodeList(self):\n",
    "        self.setInDegreeNodeList()\n",
    "        return self.inDegreeNodeList\n",
    "\n",
    "    def getOutDegreeNodeList(self):\n",
    "        self.setOutDegreeNodeList()\n",
    "        return self.outDegreeNodeList\n",
    "    \n",
    "    def setNodeList(self):\n",
    "        i = 0\n",
    "        while i < self.graphSize: \n",
    "            self.nodeList.append(i)\n",
    "            i += 1\n",
    "            \n",
    "    def getNodeList(self):\n",
    "        self.setNodeList()\n",
    "        return self.nodeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gr=[]\n",
    "\n",
    "for i in res:\n",
    "    gr.append(Graph(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NMSimilarity():\n",
    "    ga=0\n",
    "    gb=0\n",
    "    def __init__(self, graphA, graphB, epsilon):\n",
    "        self.graphA = graphA\n",
    "        self.graphB = graphB\n",
    "        self.epsilon = epsilon\n",
    "        self.inNodeListA = graphA.getInDegreeNodeList()\n",
    "        self.outNodeListA = graphA.getOutDegreeNodeList()\n",
    "        self.inNodeListB = graphB.getInDegreeNodeList()\n",
    "        self.outNodeListB = graphB.getOutDegreeNodeList()\n",
    "        self.graphSizeA = graphA.getGraphSize()\n",
    "        ga=graphA.getGraphSize()\n",
    "        self.graphSizeB = graphB.getGraphSize()\n",
    "        gb=graphB.getGraphSize()\n",
    "        self.nodeSimilarity = [[0 for x in range(ga)] for y in range(gb)]\n",
    "        self.inNodeSimilarity = [[0 for x in range(ga)] for y in range(gb)]\n",
    "        self.outNodeSimilarity = [[0 for x in range(ga)] for y in range(gb)]\n",
    "        \n",
    "        \n",
    "    def initializeSimilarityMatrices(self):\n",
    "        for i in range(0,self.graphSizeA):\n",
    "            for j in range(0,self.graphSizeB):\n",
    "                maxDegree = float(max(len(self.inNodeListA[i]),len(self.inNodeListB[j])))\n",
    "                if maxDegree != 0:\n",
    "                    self.inNodeSimilarity[i][j] = ((min(len(self.inNodeListA[i]), len(self.inNodeListB[j]))) / (maxDegree))\n",
    "                else:\n",
    "                    self.inNodeSimilarity[i][j] = float(0.0)\n",
    "\n",
    "\n",
    "                maxDegree = float(max(len(self.outNodeListA[i]), len(self.outNodeListB[j])));\n",
    "                if maxDegree != 0:\n",
    "                    self.outNodeSimilarity[i][j] = ((min(len(self.outNodeListA[i]), len(self.outNodeListB[j]))) / (maxDegree))\n",
    "                else:\n",
    "                    self.outNodeSimilarity[i][j] = float(0.0)\n",
    "\n",
    "        for i in range(0,self.graphSizeA):\n",
    "            for j in range(0,self.graphSizeB) :\n",
    "                self.nodeSimilarity[i][j] = (self.inNodeSimilarity[i][j] + self.outNodeSimilarity[i][j])\n",
    "        \n",
    "    def enumerationFunction(self, neighborListMin, neighborListMax, graph):\n",
    "        similaritySum = 0.0\n",
    "        valueMap = {}\n",
    "        if graph == 0:\n",
    "            l1=len(neighborListMin)\n",
    "            for i in range(0,l1):\n",
    "                node=neighborListMin[i]\n",
    "                maxi=0.0\n",
    "                maxIndex=-1\n",
    "                l2=len(neighborListMax)\n",
    "                for j in range(0,l2):\n",
    "                    key=neighborListMax[j]\n",
    "                    if key not in valueMap:\n",
    "                        try:\n",
    "                            if maxi < self.nodeSimilarity[node][key]:\n",
    "                                maxi = self.nodeSimilarity[node][key]\n",
    "                                maxIndex = key\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                        continue\n",
    "                valueMap[maxIndex]=maxi\n",
    "        else:\n",
    "            for i in range(len(neighborListMin)):\n",
    "                node=neighborListMin[i]\n",
    "                maxi=0.0\n",
    "                maxIndex=-1\n",
    "                for j in range(len(neighborListMax)):\n",
    "                    key=neighborListMax[j]\n",
    "                    if key not in valueMap:\n",
    "                        try:\n",
    "                            if maxi < self.nodeSimilarity[key][node]:\n",
    "                                maxi = self.nodeSimilarity[key][node]\n",
    "                                maxIndex = key\n",
    "                        except IndexError:\n",
    "                            pass\n",
    "                        continue\n",
    "                valueMap[maxIndex]=maxi\n",
    "        valu=0.0       \n",
    "        for val in valueMap.itervalues():\n",
    "            valu=valu+float(val)\n",
    "        similaritySum=valu\n",
    "        return similaritySum\n",
    "        \n",
    "        \n",
    "        \n",
    "    def measureSimilarity(self):\n",
    "        maxDifference = 0.0\n",
    "        terminate = False\n",
    "        while not terminate:\n",
    "            maxDifference = 0.0\n",
    "            for i in range(0, self.graphSizeA):\n",
    "                for j in range(0, self.graphSizeB):\n",
    "                    similaritySum = 0.0\n",
    "                    try:\n",
    "                        maxDegree = float(max(len(self.inNodeListA[i]), len(self.inNodeListB[j])))\n",
    "                        minDegree = int(min(len(self.inNodeListA[i]), len(self.inNodeListB[j])))\n",
    "                        # calculate in-degree similarities\n",
    "                        if minDegree == len(self.inNodeListA[i]):\n",
    "                            similaritySum = self.enumerationFunction(self.inNodeListA[i], self.inNodeListB[j], 0)\n",
    "                        else:\n",
    "                            similaritySum = self.enumerationFunction(self.inNodeListB[j], self.inNodeListA[i], 1)\n",
    "                        if maxDegree == 0.0 and similaritySum == 0.0:\n",
    "                            self.inNodeSimilarity[i][j] = 1.0\n",
    "                        elif maxDegree == 0.0:\n",
    "                            self.inNodeSimilarity[i][j] = 0.0\n",
    "                        else:\n",
    "\n",
    "                            self.inNodeSimilarity[i][j]=float(similaritySum / maxDegree)\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    continue\n",
    "                    similaritySum = 0.0\n",
    "                    try:\n",
    "                        maxDegree = float(max(len(self.outNodeListA[i]), len(self.outNodeListB[j])));\n",
    "                        minDegree = int(min(len(self.outNodeListA[i]), len(self.outNodeListB[j])));\n",
    "                        if minDegree == len(self.outNodeListA[i]):\n",
    "                            similaritySum = self.enumerationFunction(self.outNodeListA[i], self.outNodeListB[j], 0)\n",
    "                        else:\n",
    "                            similaritySum = self.enumerationFunction(self.outNodeListB[j], self.outNodeListA[i], 1)\n",
    "                        if maxDegree == 0.0 and similaritySum == 0.0:\n",
    "                            self.outNodeSimilarity[i][j] = 1.0\n",
    "                        elif maxDegree == 0.0:\n",
    "                            self.outNodeSimilarity[i][j] = 0.0\n",
    "                        else:\n",
    "                            self.outNodeSimilarity[i][j] = similaritySum / maxDegree\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    continue\n",
    "\n",
    "\n",
    "            for i in range(0,self.graphSizeA):\n",
    "                for j in range(0,self.graphSizeB):\n",
    "                    try:\n",
    "                        temp = (self.inNodeSimilarity[i][j] +self.outNodeSimilarity[i][j]);\n",
    "                        if abs(self.nodeSimilarity[i][j] - temp) > maxDifference:\n",
    "                            maxDifference = abs(self.nodeSimilarity[i][j] - temp)\n",
    "                        self.nodeSimilarity[i][j] = temp\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "                    continue\n",
    "\n",
    "\n",
    "            if maxDifference < self.epsilon:\n",
    "                terminate = True\n",
    " \n",
    "    def getGraphSimilarity(self):\n",
    "        finalGraphSimilarity = 0.0\n",
    "        self.measureSimilarity()\n",
    "        \n",
    "        if self.graphA.getGraphSize() < self.graphB.getGraphSize():\n",
    "            finalGraphSimilarity = self.enumerationFunction(self.graphA.getNodeList(), self.graphB.getNodeList(), 0) / self.graphA.getGraphSize()\n",
    "        else:\n",
    "            finalGraphSimilarity = self.enumerationFunction(self.graphB.getNodeList(), self.graphA.getNodeList(), 1) / self.graphB.getGraphSize()\n",
    "        finalGraphSimilarity = float('{:f}'.format(finalGraphSimilarity * 100))\n",
    "        return finalGraphSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.846154"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm=NMSimilarity(gr[11],gr[95],0.0001)\n",
    "nm.getGraphSimilarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(nm.getGraphSimilarity()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aten=np.zeros((11,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,11):\n",
    "    for j in range(0,11):\n",
    "        if i!=j:\n",
    "            nm=NMSimilarity(gr[i],gr[j],0.0001)\n",
    "            aten[i][j]=int(nm.getGraphSimilarity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(aten)\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
